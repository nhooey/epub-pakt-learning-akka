<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Staying responsive under load</title><link rel="stylesheet" href="epub.css" type="text/css"></link><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"></meta></head><body id="page"><div style="display:none;"><a id="GBS.0224.01"></a></div><div title="Staying responsive under load" class="section"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec50"></a>Staying responsive under load</h1></div></div></div><p>We&#39;ve now looked at how we can drop messages if we get overwhelmed. This lets our application stay up instead of running out of memory if the mailbox gets too full.</p><p>Let&#39;s take a minute to look at what happens with our application once it gets under a very heavy load now.</p><p>The application is humming along, and then some promotion of your app happens again and sends<a id="GBS.0224.02"></a> way more traffic to the<a id="id514" class="indexterm"></a> site than we anticipate or are provisioned to handle. Just as before, more messages start coming in than we have the capacity to handle, so they begin to build up in the mailbox. It starts to take longer to handle a given message because we have to handle the backlog of messages in the mailbox first.</p><p>Eventually, under the continued heavy load, the mailbox will reach the<a id="GBS.0224.03"></a> bounded limit we configured. At this point, it will start dropping messages. If we had used the blocking bounded mailbox, then the thread would sit and wait until the message could be placed in the mailbox. Either way, now we have a way of ensuring our application doesn&#39;t crash.</p><p>But is this a good solution? We<a id="id515" class="indexterm"></a> can look at the bounded mailbox capacity at a few levels and determine how we can expect<a id="GBS.0224.04"></a> our applications to behave:</p><div class="itemizedlist"><ul class="itemizedlist"><li style="list-style-type: disc;" class="listitem">If we have a very small bounded mailbox, any spikes in traffic will cause messages to be lost, which the application might be able to respond to in a reasonable amount of time</li><li style="list-style-type: disc;" class="listitem">If we have a very large bounded mailbox, the requests will likely time out before the actor can reply to them</li></ul></div><p>In either case, the user has to wait for the timeout to occur. If the mailbox is very<a id="GBS.0224.05"></a> small, the dropped message will simply disappear and, so, anyone waiting on a reply will timeout and fail. If the mailbox is very large or unbounded, even if the message is eventually processed, anyone waiting for a reply will eventually timeout and fail, for example, in their browser or dependent application. You&#39;ll have to evaluate your use case to see if either of these are suitable&#8212;if you don&#39;t<a id="GBS.0225.01"></a> care about the response or can tolerate messages being lost during spikes in traffic, then these may be acceptable.</p><p>For most cases, in real-time systems, waiting for very long periods of time is not acceptable, especially waiting just to receive an error.</p><div title="Circuit breakers" class="section"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec86"></a>Circuit breakers</h2></div></div></div><p>With responsiveness as a <a id="id516" class="indexterm"></a>goal in our systems, any of the situations where we make users wait for failure are not really acceptable.<a id="GBS.0225.02"></a> Similarly, with resiliency as a goal, allowing systems to become overwhelmed with messages to the point that a component fails completely is not acceptable either.</p><p>Circuit breaker is a pattern where some path through your application is monitored for the latency of the responses or error. Messages pass through the circuit breaker as they normally would, with the response time on the messages being<a id="GBS.0225.03"></a> measured. This state is &quot;closed.&quot;</p><div class="mediaobject"><img src="graphics/B04006_07_06.jpg" alt="Circuit breakers"></img><a id="GBS.0225.04"></a></div><p>Once a certain latency <a id="id517" class="indexterm"></a>threshold is reached, the circuit breaker will change states to &#39;open&#39; and will immediately fail all requests.</p><div class="mediaobject"><img src="graphics/B04006_07_07.jpg" alt="Circuit breakers"></img><a id="GBS.0226.01"></a></div><p>Then, after a period of time, the circuit breaker will change states to &quot;&#39;half-open&#39;&quot; and try sending a request.</p><div class="mediaobject"><img src="graphics/B04006_07_08.jpg" alt="Circuit breakers"></img><a id="GBS.0226.02"></a></div><p>If the request comes back<a id="id518" class="indexterm"></a> quickly, we can assume that the service has recovered and the circuit breaker can change states back to &quot;open&quot;.</p><p>It turns out that this is exactly what we want.</p><p>If the circuit breaker opens, in this condition this system gains the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li style="list-style-type: disc;" class="listitem"><span class="strong"><strong>Responsiveness</strong></span>: The service will respond with failures quickly</li><li style="list-style-type: disc;" class="listitem"><span class="strong"><strong>Resiliency</strong></span>: Instead of overwhelming downstream services until they<a id="GBS.0226.03"></a> crash, the circuit breaker will let them recover</li></ul></div><p>Note that the circuit breaker will also respond to errors the same way as timeouts. If many errors are occurring, it will also cause the circuit breaker to open. The Akka circuit breaker does not discriminate between timeouts and other failures (this is probably what we want!) but you can certainly implement your own if you want to change that behavior.<a id="GBS.0226.04"></a> If a downstream system starts failing under heavy load, we can often make similar assumptions&#8212;that it needs time to recover from the load&#8212;so, often the circuit breaker pattern will be a good idea to implement in order to protect downstream systems.</p><div title="Circuit breaker listeners" class="section"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec83"></a>Circuit breaker listeners</h3></div></div></div><p>We might not know exactly how <a id="id519" class="indexterm"></a>and when our circuit breakers will trip when we put them into production. So, what we want<a id="GBS.0226.05"></a> to do is to collect data. Remember, we always want to measure any assertions we make about how things actually perform as we&#39;re often very, very wrong.</p><p>Fortunately, the circuit breaker has hooks that let us add behavior on the different events that occurâ€”<code class="literal">onOpen</code>, <code class="literal">onClose</code>, and <code class="literal">onHalfOpen</code>.</p><p>You want to alert, or at least log, on these events so that you can determine how your circuit breakers are<a id="GBS.0227.01"></a> behaving.</p></div><div title="Circuit breaker examples" class="section"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec84"></a>Circuit breaker examples</h3></div></div></div><p>Circuit breakers work<a id="id520" class="indexterm"></a> on futures, not on actors, so they have a use beyond only using them for actors. Even if you&#39;re not using Akka in your project, you should consider whether circuit breakers can be used to protect your systems.</p><p>We&#39;ll have a look at a simple <code class="literal">CircuitBreaker</code> example now in front of a service that takes some time to respond. For the example,<a id="GBS.0227.02"></a> we&#39;ll use a local actor, but we&#39;ll add a delay to the response to simulate network time and processing time.</p><p>To see the circuit breaker in action, we&#39;ll make a producer that produces messages at a slightly faster rate than the target actor can handle. We&#39;ll make a producer that produces messages every 50 ms and we&#39;ll make the consumer take 70 ms to respond. This way, messages will slowly queue<a id="GBS.0227.03"></a> and the response times will get larger and larger until the circuit breaker trips.</p><p>We&#39;ll use the key-value store example again and introduce the 70 ms delay.</p><p>In Java:</p><div class="informalexample"><pre class="programlisting">                        match(GetRequest.class, message -&gt; { Thread.sleep(70); //slow down the actor&#39;s response Object value = map.get(message.key); Object response = (value != null) ? value : new Status.Failure(new KeyNotFoundException(message.key<a id="GBS.0227.04"></a>)); sender().tell(response, self());</pre></div><p>In Scala:</p><div class="informalexample"><pre class="programlisting">    case GetRequest(key) =&gt; Thread.sleep(70) val response: Option[Object] = map.get(key) response match { case Some(x) =&gt; sender() ! x case None =&gt; sender() ! Status.Failure(new KeyNotFoundException(key)) }</pre></div><p>In our calling class, we&#39;ll create a circuit breaker that will trip when latency becomes greater than one second.</p><p>In Java:</p><div class="informalexample"><pre class="programlisting">CircuitBreaker breaker<a id="GBS.0227.05"></a> = new CircuitBreaker(system.scheduler(), 10, FiniteDuration.create(1, &quot;second&quot;), FiniteDuration.create(1, &quot;second&quot;), system.dispatcher()). onOpen(() -&gt; { System.out.println(&quot;circuit breaker opened!&quot;); }). onClose(() -&gt; { System.out.println(&quot;circuit breaker opened!&quot;); }). onHalfOpen(() -&gt; { System.out.println(&quot;circuit breaker opened!&quot;); });</pre></div><p>In <a id="id521" class="indexterm"></a>Scala:</p><div class="informalexample"><pre class="programlisting">val breaker = new CircuitBreaker(system.scheduler,<a id="GBS.0228.01"></a> maxFailures = 10, callTimeout = 1 seconds, resetTimeout = 1 seconds). onOpen(println(&quot;circuit breaker opened!&quot;)). onClose(println(&quot;circuit breaker closed!&quot;)). onHalfOpen(println(&quot;circuit breaker half-open&quot;))</pre></div><p>You can see the parameter names in the Scala exampleâ€”they are equivalent. We build the CircuitBreaker with the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li style="list-style-type: disc;" class="listitem">Max number of failures before the breaker trips (either timeout or<a id="GBS.0228.02"></a> failure in the future)</li><li style="list-style-type: disc;" class="listitem">The call timeout (what latency to fail at)</li><li style="list-style-type: disc;" class="listitem">The reset timeout (how long to wait before changing to half-open and trying a request)</li></ul></div><p>Then, we also register a log event on the circuit breaker opening, changing state to half open and changing the state to close.</p><p>Using the circuit breaker is simpleâ€”we supply a <code class="literal">0-argument</code> lambda that returns a future (a <code class="literal">producer</code> function.) For our<a id="GBS.0228.03"></a> example, we&#39;ll use <code class="literal">ask</code>.</p><p>We&#39;ll make a call every 50 ms, and the actor will respond in 70 ms, so the messages will queue. Then the mailbox will fill, response times will balloon, and eventually the circuit breaker will open.</p><p>In Java:</p><div class="informalexample"><pre class="programlisting">        Timeout timeout = Timeout.apply(2000); ActorRefdb = system.actorOf(Props.create(SlowAkkademyDb.class)); Await.result(Patterns.ask(db, new SetRequest(&quot;key&quot;,<a id="GBS.0228.04"></a> &quot;value&quot;),  timeout), timeout.duration()); for(inti=0; i&lt;10000000; i++){ Future future = breaker.callWithCircuitBreaker(() -&gt;Patterns.ask(db, new GetRequest(&quot;key&quot;),  timeout)); toJava(future).handle((x,t) -&gt; { if(t != null){ System.out.println(&quot;got it: &quot; + x); }else{ System.out.println(&quot;error: &quot; + t.toString()); } return null; }); Thread.sleep(50); }</pre></div><p>In Scala:</p><div class="informalexample"><pre class="programlisting">  implicit val timeout = Timeout(2<a id="GBS.0228.05"></a> seconds) valdb = system.actorOf(Props[FastSlowAkkademyDb]) Await.result(db ? SetRequest(&quot;key&quot;, &quot;value&quot;), 2 seconds) (1 to 1000000).map(x =&gt; { Thread.sleep(50) valaskFuture = breaker.withCircuitBreaker(db ? GetRequest(&quot;key&quot;)) askFuture.map(x =&gt; &quot;got it: &quot; + x).recover({ case t =&gt; &quot;error: &quot; + t.toString }).foreach(x =&gt;println(x)) })</pre></div><p>In some cases, you<a id="id522" class="indexterm"></a> might want to roll out your own circuit breaker<a id="GBS.0229.01"></a> or be careful with what you consider to be a failure in a future. The circuit breaker counts any and all failures and will trip after the maxFailures is reached. If your futures fail in ways that you don&#39;t want your circuit breaker to fail, you can wrap the responses in a <code class="literal">Try</code> instead of failing the future so that the future is successful.</p><p>There is one more strategy that you can think about to<a id="GBS.0229.02"></a> overcome overwhelming your consumers. If you have a hot producer&#8212;something that will endlessly send requests&#8212;then you might want to turn the way you supply messages around so that actors ask for messages to process instead of simply receiving endless piles of messages.</p><p>Another related concept&#8212;&quot;Back-Pressure&quot;&#8212;talks about slowing down the flow of messages to what the slowest consumer can handle<a id="GBS.0229.03"></a> to avoid overwhelming downstream systems. You can certainly implement something like this yourself but the Reactive Streams proposal deals with this specific problem with a defined standard.</p><p>From <a href="https://www.reactive-streams.org/" class="ulink">https://www.reactive-streams.org/</a>â€”Reactive Streams<a id="id523" class="indexterm"></a> is an initiative to <a id="id524" class="indexterm"></a>provide a standard for asynchronous stream processing with non-blocking back pressure. This encompasses efforts aimed at runtime<a id="GBS.0229.04"></a> environments (JVM and JavaScript) as well as network protocols.</p><p>There are now <a id="id525" class="indexterm"></a>multiple implementations of Reactive Streams, including one from the Akka team (Akka Streams). Reactive Streams is a fairly large topic, so we won&#39;t introduce the technologies here, but know that people are working on this problem actively and it might be worth looking at Reactive Streams&#8212;in particular if you have &quot;hot&quot;<a id="GBS.0229.05"></a> producers that have a nearly endless supply of requests that they can make.</p><p>Reactive Streams take a blend of approaches, both receiving requests with a mechanism to slow flow down if a service becomes overwhelmed (back-pressure) and asking for extra work if there is capacity in the pipe line.</p><p>Reactive Streams is an exciting topic, but is still in its infancy at the time of writing. Akka Streams<a id="GBS.0230.01"></a> is still marked experimental but is nearing GA and Typesafe are spending a lot of time in holding seminars and letting people know about the progress in the space.</p><p>You can learn more about Reactive Streams <a id="id526" class="indexterm"></a>at <a href="http://www.reactive-streams.org/" class="ulink">http://www.reactive-streams.org/</a>.</p><p>The Akka Streams Reactive Streams<a id="id527" class="indexterm"></a> implementation documentation can be found at <a href="http://doc.akka.io/docs/akka-stream-and-http-experimental/snapshot/" class="ulink">http://doc.akka.io/docs/akka-stream-and-http-experimental/snapshot/</a>.</p></div></div></div><div style="display:none;"><a id="GBS.0230.02"></a></div></body></html>