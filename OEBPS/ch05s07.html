<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Summary</title><link rel="stylesheet" href="epub.css" type="text/css"></link><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"></meta></head><body id="page"><div style="display:none;"><a id="GBS.0177.01"></a></div><div title="Summary" class="section"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec38"></a>Summary</h1></div></div></div><p>In this chapter, we looked at two major concepts: scaling up a local application to take advantage of multicore hardware and isolating work into separate dispatchers to protect portions of the isolation from performance risks that may be encountered in other portions of the application.</p><p>To scale up, we need to do work concurrently, so we looked at several techniques for parallelizing<a id="GBS.0177.02"></a> work. We examined how to parallelize with futures and with actors. Then, we looked at how to examine an application to determine how separate work should be isolated into different dispatchers for different types of work such as computationally heavy work or blocking IO. Because the isolated dispatchers get tied up without impacting other ones, we can ensure that the other areas of the application<a id="GBS.0177.03"></a> remain responsive.</p><p>In the next chapter, we will build on the concepts here to look at how we can start to distribute load across multiple machines.</p></div><div style="display:none;"><a id="GBS.0177.04"></a></div></body></html>